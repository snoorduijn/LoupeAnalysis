{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Projection\n",
    "#import os\n",
    "#os.environ['PROJ_LIB'] = 'C:\\\\Users\\\\noo029\\\\Anaconda3\\\\envs\\\\py310\\\\Library\\\\share\\\\proj'\n",
    "#os.environ['GDAL_DATA'] = 'C:\\\\Users\\\\noo029\\\\Anaconda3\\\\envs\\\\py310\\\\Library\\\\share'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loupe_header(loupe_fn, header_line_num):\n",
    "    with open(loupe_fn, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        loupe_header = lines[header_line_num].split() \n",
    "    return loupe_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File names: Loupe and Catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loupe_fn = '20240916_mallee_cliffs.dat' # 'Kartoo_2024_02_13.dat'\n",
    "catalyst_fn = '2024_09_17_Catalyst_Loupe_MalleeCliffs.csv'# '2024-02-13-Kartoo.csv'\n",
    "epsg_loupe = \"EPSG:32754\"\n",
    "epsg_catalyst = \"EPSG:7854\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Loupe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header_line_num = 6\n",
    "\n",
    "with open(loupe_fn, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    full_loupe_header = lines[0:header_line_num] \n",
    "\n",
    "loupe_full_df = (pd.read_csv(loupe_fn, skiprows=7, delim_whitespace=True, header=None, \n",
    "                        names=get_loupe_header(loupe_fn, header_line_num))\n",
    "            .dropna(how='all')\n",
    "            .dropna())\n",
    "\n",
    "loupe_df = (pd.read_csv(loupe_fn, skiprows=7, delim_whitespace=True, header=None, \n",
    "                       names=get_loupe_header(loupe_fn, header_line_num))\n",
    "            .dropna(subset=['TIME', 'EAST', 'NORTH', 'HEIGHT'], how='any')\n",
    "            [['TIME', 'EAST', 'NORTH', 'HEIGHT', 'C']]\n",
    "            .assign(TIME=lambda df: pd.to_datetime(df['TIME'], format='ISO8601'),\n",
    "                    EAST=lambda df: pd.to_numeric(df['EAST'], errors='coerce'),\n",
    "                    NORTH=lambda df: pd.to_numeric(df['NORTH'], errors='coerce'),\n",
    "                    HEIGHT=lambda df: pd.to_numeric(df['HEIGHT'], errors='coerce'))\n",
    "            .dropna(how='all')\n",
    "            .rename(columns={\"TIME\":'time',\n",
    "                             'EAST':'x',\n",
    "                             'NORTH':'y',\n",
    "                             'HEIGHT':'z'\n",
    "                            })\n",
    "            .dropna()\n",
    "            )\n",
    "\n",
    "loupeX_df = loupe_df[loupe_df.C == 'X']\n",
    "\n",
    "loupe_gdf = gpd.GeoDataFrame(\n",
    "    loupeX_df, \n",
    "    geometry=gpd.points_from_xy(loupeX_df['x'], loupeX_df['y']), \n",
    "    crs=epsg_loupe)\n",
    "\n",
    "loupe_gdf ['time'] = loupe_gdf.time.astype(str)\n",
    "\n",
    "loupe_gdf.to_file(f'{loupe_fn[:-4]}.shp')\n",
    "\n",
    "loupeX_df = loupeX_df.set_index('time')\n",
    "\n",
    "print(loupeX_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Catalyst data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_coln, y_coln, x_coln, z_coln = \"Gnss DateTime (Local Time)\",\" Northing(m)\",\" Easting(m)\",\" Height MSL(m)\"\n",
    "\n",
    "catalyst_df = pd.read_csv(catalyst_fn)[[time_coln, y_coln, x_coln, z_coln]]   \n",
    "dt_format = '%d/%m/%Y %I:%M:%S %p (%Z%z)' \n",
    "t = catalyst_df[time_coln].tolist()[0]    \n",
    "print(t)\n",
    "# check datetime format compatability\n",
    "try:\n",
    "    dum = datetime.strptime(t, dt_format)\n",
    "    print(\"File datetime format able to be converted!\")\n",
    "except ValueError:\n",
    "    print(f'Check datetime format in file:{catalyst_fn}')\n",
    "    exit\n",
    "\n",
    "# the colons in the \"14/09/2023 12:57:27 PM (UTC+12:00)\" needs to be removed to allow datetime.strptime to recognise the UTC timezone: https://protect-au.mimecast.com/s/jggLCL7EAOCwrkXAhmfJvX?domain=docs.python.org\n",
    "#dt_format = '%d/%m/%Y %I:%M:%S %p (%Z%z)'  # 13/02/2024 2:28:03 PM (UTC+10.5:30) -> \"14/09/2023 12:57:27 PM (UTC+1200)\"   \n",
    "#catalyst_df[time_coln] = [datetime.strptime(t[:-6]+t[-3:], dt_format) for t in catalyst_df[time_coln]]   \n",
    "catalyst_df[time_coln] = [datetime.strptime(t, dt_format) for t in catalyst_df[time_coln]]   \n",
    "print(catalyst_df[time_coln][:10])\n",
    "\n",
    "catalyst_df = (catalyst_df.assign(time_utc=lambda df: \n",
    "                        df[time_coln].dt.tz_convert('UTC'))\n",
    "                .rename(columns={'time_utc':'time',\n",
    "                                x_coln:'x', \n",
    "                                y_coln:'y', \n",
    "                                z_coln:'z'}\n",
    "                )[['time', 'x', 'y', 'z']]\n",
    ")\n",
    "\n",
    "#%% Timestamp analysis\n",
    "# catalyst_gdf = catalyst_gdf.assign(sec_prev=lambda df: (df['time'].diff().seconds))\n",
    "nidx = pd.date_range(catalyst_df.time.min(), catalyst_df.time.max(), freq='1s')\n",
    "catalyst_df = catalyst_df.set_index('time').sort_index()\n",
    "catalyst_df['data_source'] = 'original_xyz' \n",
    "\n",
    "catalyst_df_new = catalyst_df.reindex(nidx)\n",
    "catalyst_df_new[['x', 'y', 'z']] = catalyst_df_new[['x', 'y', 'z']].interpolate()\n",
    "catalyst_df_new['data_source'] = catalyst_df_new['data_source'].fillna('interpolate_xyz')\n",
    "\n",
    "catalyst_gdf_new = gpd.GeoDataFrame(\n",
    "    catalyst_df_new, \n",
    "    geometry=gpd.points_from_xy(catalyst_df_new['x'], catalyst_df_new['y']), \n",
    "    crs=epsg_catalyst)\n",
    "catalyst_gdf_new = catalyst_gdf_new.to_crs(epsg_loupe[5:])\n",
    "\n",
    "catalyst_df_new['xx'] = catalyst_gdf_new.get_coordinates()['x'].values\n",
    "catalyst_df_new['yy'] = catalyst_gdf_new.get_coordinates()['y'].values\n",
    "\n",
    "\n",
    "catalyst_gdf_new['datetime'] = catalyst_gdf_new.index.astype(str)\n",
    "catalyst_gdf_new = catalyst_gdf_new.reset_index(drop=True)\n",
    "catalyst_gdf_new.to_file(f'{catalyst_fn[:-4]}.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Figure\n",
    "fig, ax = plt.subplots(1,1)\n",
    "loupe_gdf.plot(ax=ax, marker='*')\n",
    "catalyst_gdf_new.plot(ax=ax, column='data_source', \n",
    "                      marker='o', \n",
    "                      edgecolor='none',\n",
    "                      legend=True)\n",
    "# cx.add_basemap(ax, crs=catalyst_gdf_new.crs.to_string(), \n",
    "#                 source=cx.providers.OpenStreetMap.Mapnik)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(loupe_df.time, loupe_df.z,'k*', label=\"Loupe\")\n",
    "for idx, grp in catalyst_df_new.groupby('data_source'):\n",
    "    ax.plot(grp.index, grp.z,'+', label=f\"raw data = {idx}\")\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Elevation')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Concat data sources\n",
    "df = pd.concat([catalyst_df_new.add_prefix('cata_'), \n",
    "                loupeX_df.add_prefix('loupe_')], \n",
    "               axis=1)\n",
    "df['offset_xy'] = ((df['cata_xx'] - df['loupe_x']) ** 2 + (df['cata_yy'] - df['loupe_y']) ** 2) ** 0.5\n",
    "df.to_csv('loupe_catalyst_combined.dat')\n",
    "\n",
    "catalyst_df_new = (catalyst_df_new.reset_index(drop=False).rename(columns={'index':'time'}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def replace_values(loupe_df, catalyst_df):\n",
    "    # create a copy of the loupe_df to avoid modifying the original DataFrame\n",
    "    result_df = loupe_df.copy()\n",
    "    \n",
    "    result_df['source'] = 'Loupe'\n",
    "    # create a lookup table for the catalyst_df and rten_df time columns\n",
    "    catalyst_lookup = {t: (x, y, z) for t, x, y, z in zip(catalyst_df['time'], \n",
    "                                                          catalyst_df['xx'], \n",
    "                                                          catalyst_df['yy'], \n",
    "                                                          catalyst_df['z'])}\n",
    "    \n",
    "    # iterate over the rows in the loupe_df\n",
    "    for index, row in loupe_df.iterrows():\n",
    "        # look up the x, y, and z values for the current time in the catalyst_df and rten_df\n",
    "        x, y, z = catalyst_lookup.get(row['time'], None)\n",
    "        source = 'Catalyst'\n",
    "                \n",
    "        # replace the x, y, and z values in the result_df for the current row\n",
    "        result_df.at[index, 'x'] = x\n",
    "        result_df.at[index, 'y'] = y\n",
    "        result_df.at[index, 'z'] = z\n",
    "        result_df.at[index, 'source'] = source\n",
    "       \n",
    "    return result_df\n",
    "    \n",
    "loupe_catalyst_df = replace_values(loupe_df, catalyst_df_new)\n",
    "loupe_catalyst_df.to_csv('loupe_catalyst_replaced.dat')\n",
    "\n",
    "loupe_full_df [['EAST', 'NORTH', 'HEIGHT']] = loupe_catalyst_df[['x', 'y', 'z']]\n",
    "loupe_full_df [['EAST', 'NORTH', 'HEIGHT']] = loupe_full_df [['EAST', 'NORTH', 'HEIGHT']].round(1)\n",
    "\n",
    "with open(loupe_fn[:-4] + \"_catalyst_fix.dat\", 'w') as f:\n",
    "    f.write(\"\".join(full_loupe_header))\n",
    "    f.write(loupe_full_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
